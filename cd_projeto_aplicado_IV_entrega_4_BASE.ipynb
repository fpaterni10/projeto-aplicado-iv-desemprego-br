{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fpaterni10/projeto-aplicado-iv-desemprego-br/blob/main/cd_projeto_aplicado_IV_entrega_4_BASE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab5992f6",
      "metadata": {
        "id": "ab5992f6"
      },
      "source": [
        "\n",
        "# **Entrega 4 — Projeto Aplicado IV (Ciência de Dados EAD) - 2025/02**  \n",
        "## **Predição da Taxa de Desemprego no Brasil: Séries Temporais com Dados do CAGED, PNAD e SELIC**\n",
        "**ODS 8 — Trabalho Decente e Crescimento Econômico**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b48e24a",
      "metadata": {
        "id": "5b48e24a"
      },
      "outputs": [],
      "source": [
        "#@title **Identificação do Grupo e Opção do Projeto**\n",
        "#@markdown Integrantes do Grupo, nome completo em ordem alfabética \\(preencher abaixo\\)\n",
        "Aluno1 = 'Aline Correa de Araújo, 10414773' #@param {type:\"string\"}\n",
        "Aluno2 = 'Franciele Paterni, 10414598'      #@param {type:\"string\"}\n",
        "Aluno3 = 'Giovanna Sobral da Silva, 10424600' #@param {type:\"string\"}\n",
        "Aluno4 = 'Guilherme Soares Frota, 10416060' #@param {type:\"string\"}\n",
        "print('Integrantes:')\n",
        "for a in [Aluno1,Aluno2,Aluno3,Aluno4]:\n",
        "    if a and a.lower()!='none':\n",
        "        print(' -', a)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b780f341",
      "metadata": {
        "id": "b780f341"
      },
      "source": [
        "## Introdução\n",
        "\n",
        "O cenário econômico brasileiro é marcado por oscilações relevantes no mercado de trabalho e na taxa básica de juros (SELIC), fatores diretamente relacionados ao nível de emprego e à renda da população. Compreender esses movimentos é fundamental para a formulação de políticas públicas e para a tomada de decisão em setores estratégicos. A análise de séries temporais aplicadas ao emprego formal e ao comportamento da taxa de desocupação se torna, assim, um instrumento de previsão e planejamento, permitindo antecipar tendências e identificar padrões estruturais na economia brasileira (IBGE, 2025; BACEN, 2025).\n",
        "\n",
        "O Brasil apresenta histórico de flutuações significativas na geração de empregos formais, influenciadas por fatores macroeconômicos, políticas governamentais e ciclos econômicos. Ao mesmo tempo, a taxa SELIC impacta diretamente a dinâmica do crédito, do consumo e do investimento, refletindo-se na variação do nível de emprego. Dessa forma, existe uma motivação clara em utilizar dados oficiais e atualizados para entender a relação entre esses elementos.\n",
        "\n",
        "A justificativa central deste trabalho é que a previsão da taxa de desemprego, com base em indicadores fundamentais como o CAGED e a SELIC, oferece valor social e econômico. Tal análise apoia o **ODS 8 – Trabalho Decente e Crescimento Econômico**, ao fornecer insumos para políticas públicas voltadas à melhoria das condições do mercado de trabalho, além de gerar conhecimento relevante para gestores e pesquisadores.\n",
        "\n",
        "Desenvolveremos um modelo de séries temporais para a predição da taxa de desocupação no Brasil, explorando dados do CAGED e da PNAD, bem como informações macroeconômicas relacionadas à taxa SELIC.\n",
        "\n",
        "## Objetivos Específicos\n",
        "\n",
        "- Realizar tratamento e padronização das bases de dados selecionadas (CAGED, PNAD e SELIC);  \n",
        "- Explorar a série histórica, verificando estacionariedade, sazonalidade e ciclos;  \n",
        "- Construir e avaliar modelos de previsão, como SARIMAX e técnicas de aprendizado de máquina aplicadas a séries temporais;  \n",
        "- Comparar os resultados entre modelos estatísticos e de machine learning, verificando acurácia e robustez;  \n",
        "- Apresentar previsões e insights que possam apoiar decisões em políticas públicas e planejamento estratégico.  \n",
        "\n",
        "## Bases de Dados Utilizadas\n",
        "\n",
        "- **CAGED (Cadastro Geral de Empregados e Desempregados):** dados mensais e trimestrais de admissões, desligamentos e saldo de empregos formais (MTE, 2025).  \n",
        "\n",
        "- **PNAD Contínua – Tabela 4099**: taxas trimestrais de desocupação da população com 14 anos ou mais (IBGE, 2025).  \n",
        "\n",
        "- **Taxa SELIC (Sistema Gerenciador de Séries Temporais – SGS)** taxa básica de juros diária, agregada para análise mensal e trimestral (BACEN, 2025).  \n",
        "\n",
        "Essas bases abrangem o período de 2012 a 2025, no formato CSV, com granularidade mensal, trimestral e diária (tratada em médias para compatibilização). Todas as fontes são oficiais e públicas, permitindo a reprodução do experimento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0e2941e",
      "metadata": {
        "id": "a0e2941e"
      },
      "source": [
        "# **Pipeline da Solução**\n",
        "\n",
        "A construção da solução será guiada por um pipeline de ciência de dados estruturado em etapas claras e interdependentes, garantindo a reprodutibilidade e a consistência do projeto. O foco será a previsão da taxa de desemprego no Brasil a partir da integração de séries temporais do CAGED (admissões, desligamentos e saldo de empregos), da PNAD Contínua (taxa de desocupação) e da taxa Selic (como variável exógena).\n",
        "\n",
        "## 1. Coleta e Organização dos Dados\n",
        "- **Bases utilizadas**:  \n",
        "  - CAGED (mensal e trimestral, 2012–2025)  \n",
        "  - PNAD Contínua (taxa de desocupação trimestral, 2012–2025)  \n",
        "  - Taxa Selic (diária → mensal/trimestral, 2012–2025)  \n",
        "- **Formato**: CSV e XLSX tratados previamente.  \n",
        "- **Objetivo**: consolidar todas as bases em formato uniforme, com datas padronizadas (`datetime`).  \n",
        "\n",
        "## 2. Pré-processamento de Dados\n",
        "- Tratamento de valores ausentes e cabeçalhos duplicados.  \n",
        "- Criação de variáveis derivadas (saldo = admissões − desligamentos).  \n",
        "- Conversão da Selic diária em média mensal e trimestral.  \n",
        "- Alinhamento temporal das bases.  \n",
        "\n",
        "## 3. Componentização da Série Temporal\n",
        "- Decomposição em tendência, sazonalidade e resíduos.  \n",
        "- Análise de estacionariedade (ADF test).  \n",
        "- ACF e PACF para identificar ordens de ARIMA/SARIMA.  \n",
        "\n",
        "## 4. Análise Exploratória (EDA)\n",
        "- Visualização da evolução do desemprego, saldo do CAGED e Selic.  \n",
        "- Correlação entre séries (CAGED ↔ PNAD ↔ Selic).  \n",
        "- Identificação de períodos críticos (crises, pandemia).  \n",
        "- Estatísticas descritivas (média, variância, outliers).  \n",
        "\n",
        "## 5. Modelagem\n",
        "- Modelos estatísticos: ARIMA, SARIMA, SARIMAX.  \n",
        "- Aprendizado de Máquina: Random Forest Regressor, XGBoost.  \n",
        "- Métricas:RMSE, MAE, MAPE.  \n",
        "- Comparação de modelos para selecionar o mais robusto.  \n",
        "\n",
        "## 6. Validação e Testes\n",
        "- Split temporal (train/test).  \n",
        "- Validação cruzada para séries temporais.  \n",
        "- Testes em períodos pós-pandemia.  \n",
        "\n",
        "## 7. Produto Analítico e Visualização\n",
        "- Dashboards interativos (Plotly/Matplotlib).  \n",
        "- Gráficos de tendência e previsão com intervalos de confiança.  \n",
        "- Relatório executivo com insights e recomendações.  \n",
        "\n",
        "## 8. Entrega Final\n",
        "- Notebook reprodutível no Colab.  \n",
        "- Bases tratadas documentadas.  \n",
        "- Relatório técnico.  \n",
        "- Conexão com ODS 8 (Trabalho decente e crescimento econômico).  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "272102f9",
      "metadata": {
        "id": "272102f9"
      },
      "source": [
        "\n",
        "## Diagrama de Solução\n",
        "Figura do pipeline com o fluxo completo de dados → preparação → análise temporal → modelagem → avaliação → relatório.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68035432",
      "metadata": {
        "id": "68035432"
      },
      "outputs": [],
      "source": [
        "# Exibir diagrama salvo no Drive (ajuste BASE se necessário)\n",
        "from IPython.display import Image, display\n",
        "from pathlib import Path\n",
        "BASE = Path('/content/drive/MyDrive/BASE_DE_DADOS_REAIS')  # ajuste se necessário\n",
        "PIPE = BASE / 'out' / 'relatorio_etapa3' / 'pipeline'\n",
        "img_candidates = ['pipeline_etapa3_v4.png','pipeline_etapa3_v3.png','pipeline_etapa3.png']\n",
        "for name in img_candidates:\n",
        "    p = PIPE / name\n",
        "    if p.exists():\n",
        "        display(Image(filename=str(p)))\n",
        "        break\n",
        "else:\n",
        "    print('Diagrama não encontrado em', PIPE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abd0ddaf",
      "metadata": {
        "id": "abd0ddaf"
      },
      "source": [
        "## Setup (libs, Drive e caminhos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9027ebf",
      "metadata": {
        "id": "b9027ebf"
      },
      "outputs": [],
      "source": [
        "# Instalar libs necessárias (pode reiniciar o runtime)\n",
        "!pip -q install --upgrade lightgbm statsmodels pmdarima scikit-learn\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "BASE = Path('/content/drive/MyDrive/BASE_DE_DADOS_REAIS')  # ajuste se necessário\n",
        "SERIES = BASE / 'dados_tratados' / 'CAGED_ETAPA_2' / 'series_for_ts_analysis.csv'\n",
        "FEAT   = BASE / 'dados_tratados' / 'CAGED_ETAPA_2' / 'pnad_caged_features_prepared_v2_v3.csv'  # se existir\n",
        "OUT    = BASE / 'out' / 'relatorio_etapa3'\n",
        "print('BASE existe?', BASE.exists())\n",
        "print('SERIES existe?', SERIES.exists())\n",
        "print('FEAT existe?', FEAT.exists())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8b12c70",
      "metadata": {
        "id": "e8b12c70"
      },
      "source": [
        "\n",
        "## EDA e Pré-processamento dos dados\n",
        "- Merge PNAD + CAGED; padronização temporal trimestral.\n",
        "- Engenharia de features: **lags**, **rolling**, **asinh**, **dummies** de trimestre/regime.\n",
        "- Análise temporal: **ADF**, **ACF/PACF**, **decomposição (período=4)**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "289af74b",
      "metadata": {
        "id": "289af74b"
      },
      "outputs": [],
      "source": [
        "# Carregar séries e exibir amostra\n",
        "\n",
        "def ensure_date(df):\n",
        "    if 'date' in df.columns:\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "    elif 'periodo_tri' in df.columns:\n",
        "        df['date'] = pd.PeriodIndex(df['periodo_tri'], freq='Q').to_timestamp()\n",
        "    else:\n",
        "        raise ValueError(\"Não encontrei 'date' nem 'periodo_tri'.\")\n",
        "    return df\n",
        "\n",
        "sdf = pd.read_csv(SERIES, encoding='utf-8-sig')\n",
        "sdf = ensure_date(sdf).sort_values('date')\n",
        "print(sdf.shape)\n",
        "sdf.head(8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2db19d",
      "metadata": {
        "id": "1b2db19d"
      },
      "outputs": [],
      "source": [
        "# Exibir figuras da EDA (se existirem)\n",
        "from IPython.display import Image, display\n",
        "TS = OUT / 'ts_plots'\n",
        "DECOMP = OUT / 'decomposition'\n",
        "show = [\n",
        "    TS/'acf_tx_desocupacao.png', TS/'pacf_tx_desocupacao.png',\n",
        "    TS/'acf_caged_saldo_tri.png', TS/'pacf_caged_saldo_tri.png',\n",
        "    DECOMP/'decomp_tx_desocupacao.png', DECOMP/'decomp_caged_saldo_tri.png'\n",
        "]\n",
        "for p in show:\n",
        "    if p.exists(): display(Image(filename=str(p)))\n",
        "    else: print('Não achei:', p)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba71ec6d",
      "metadata": {
        "id": "ba71ec6d"
      },
      "source": [
        "\n",
        "## Modelo base — LGBM (campeão em holdout)\n",
        "- Métricas (holdout): **MAE ≈ 0,2966**, **RMSE ≈ 0,3481**.\n",
        "- Figuras: Real vs Pred calibrado; Resíduos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eee22e6",
      "metadata": {
        "id": "1eee22e6"
      },
      "outputs": [],
      "source": [
        "# Exibir figuras do LGBM (se existirem)\n",
        "from IPython.display import Image, display\n",
        "p1 = OUT / 'real_vs_pred_calibrado.png'\n",
        "p2 = OUT / 'residuos_calibrado.png'\n",
        "for p in [p1,p2]:\n",
        "    if p.exists(): display(Image(filename=str(p)))\n",
        "    else: print('Não achei:', p)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d9dda27",
      "metadata": {
        "id": "4d9dda27"
      },
      "source": [
        "\n",
        "## Modelo estatístico — SARIMAX\n",
        "- Especificação selecionada: **(1,1,2) × (1,0,1,4)** com exógenas do CAGED.\n",
        "- Métricas (teste): **MAE ≈ 0,362**, **RMSE ≈ 0,433**, **MAPE ≈ 5,54%**.\n",
        "- Figuras: Real vs Pred, Resíduos, ACF dos resíduos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c7d9129",
      "metadata": {
        "id": "4c7d9129"
      },
      "outputs": [],
      "source": [
        "# Exibir figuras do SARIMAX (se existirem) + ler métricas do CSV/JSON se houver\n",
        "from IPython.display import Image, display\n",
        "import json\n",
        "SARIMAX_DIR = OUT / 'modelos' / 'sarimax'\n",
        "SARIMAX_FIG = SARIMAX_DIR / 'figs'\n",
        "imgs = [\n",
        "    SARIMAX_FIG/'sarimax_real_vs_pred.png',\n",
        "    SARIMAX_FIG/'sarimax_residuos.png',\n",
        "    SARIMAX_FIG/'sarimax_residuos_acf.png'\n",
        "]\n",
        "for p in imgs:\n",
        "    if p.exists(): display(Image(filename=str(p)))\n",
        "    else: print('Não achei:', p)\n",
        "\n",
        "pred_path = SARIMAX_DIR / 'sarimax_predictions_test.csv'\n",
        "if pred_path.exists():\n",
        "    pred = pd.read_csv(pred_path, parse_dates=['date'], index_col='date')\n",
        "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "    import numpy as np\n",
        "    mae = mean_absolute_error(pred['y_test'], pred['y_hat'])\n",
        "    rmse = np.sqrt(mean_squared_error(pred['y_test'], pred['y_hat']))\n",
        "    mape = (np.abs((pred['y_test']-pred['y_hat'])/pred['y_test']).replace([np.inf,-np.inf], np.nan).dropna().mean())*100\n",
        "    print({'MAE':round(mae,3),'RMSE':round(rmse,3),'MAPE_%':round(mape,2)})\n",
        "else:\n",
        "    print('Predições de teste do SARIMAX não encontradas em', pred_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ec57d4d",
      "metadata": {
        "id": "4ec57d4d"
      },
      "source": [
        "\n",
        "## Backtest (rolling-origin, expanding window)\n",
        "Avaliação robusta simulando linha do tempo real para **SARIMAX** e **LGBM**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c337169",
      "metadata": {
        "id": "1c337169"
      },
      "outputs": [],
      "source": [
        "# Funções de backtest — SARIMAX e LGBM\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# preparar y e X\n",
        "sdf2 = sdf.set_index('date').copy()\n",
        "y = sdf2['tx_desocupacao'].astype(float)\n",
        "exog_cols = [c for c in ['caged_saldo_tri','caged_roll3_asinh'] if c in sdf2.columns]\n",
        "X = sdf2[exog_cols].copy() if exog_cols else None\n",
        "if X is not None:\n",
        "    X = X.join(X.shift(1).add_suffix('_lag1'))\n",
        "\n",
        "# SARIMAX backtest (1 passo à frente)\n",
        "def sarimax_backtest(y, X=None, order=(1,1,2), seasonal=(1,0,1,4), initial=36):\n",
        "    idx = y.index; preds=[]; reals=[]\n",
        "    for t in range(initial, len(y)):\n",
        "        y_tr = y.iloc[:t]\n",
        "        X_tr = X.iloc[:t] if X is not None else None\n",
        "        X_te = X.iloc[t:t+1] if X is not None else None\n",
        "        res  = SARIMAX(y_tr, exog=X_tr, order=order, seasonal_order=seasonal,\n",
        "                       enforce_stationarity=False, enforce_invertibility=False).fit(disp=0)\n",
        "        p    = res.get_forecast(steps=1, exog=X_te).predicted_mean.iloc[0]\n",
        "        preds.append(p); reals.append(y.iloc[t])\n",
        "    bt = pd.DataFrame({'real':reals,'pred':preds}, index=idx[initial:])\n",
        "    mae = mean_absolute_error(bt.real, bt.pred)\n",
        "    rmse= np.sqrt(mean_squared_error(bt.real, bt.pred))\n",
        "    return bt, mae, rmse\n",
        "\n",
        "bt_sx, mae_sx, rmse_sx = sarimax_backtest(y, X)\n",
        "print('Backtest SARIMAX → MAE=', round(mae_sx,3), 'RMSE=', round(rmse_sx,3))\n",
        "\n",
        "# LGBM backtest (expanding, 1 passo)\n",
        "import lightgbm as lgb\n",
        "cand = ['caged_roll3_asinh','caged_lag1_asinh','caged_asinh_k','caged_yoy_w','post_2021','interaction_roll_post']\n",
        "features = [c for c in cand if c in sdf2.columns]\n",
        "\n",
        "df_ml = sdf2[features + ['tx_desocupacao']].dropna().copy()\n",
        "\n",
        "def lgbm_backtest(df_ml, features, initial=36):\n",
        "    idx = df_ml.index\n",
        "    preds, reals = [], []\n",
        "    for t in range(initial, len(df_ml)):\n",
        "        train = df_ml.iloc[:t]\n",
        "        test1 = df_ml.iloc[t:t+1]\n",
        "        model = lgb.LGBMRegressor(n_estimators=300, random_state=42)\n",
        "        model.fit(train[features], train['tx_desocupacao'])\n",
        "        p = float(model.predict(test1[features]))\n",
        "        preds.append(p); reals.append(float(test1['tx_desocupacao'].iloc[0]))\n",
        "    bt = pd.DataFrame({'real':reals,'pred':preds}, index=idx[initial:])\n",
        "    mae = mean_absolute_error(bt.real, bt.pred)\n",
        "    rmse= np.sqrt(mean_squared_error(bt.real, bt.pred))\n",
        "    return bt, mae, rmse\n",
        "\n",
        "if features:\n",
        "    bt_lgb, mae_lgb, rmse_lgb = lgbm_backtest(df_ml, features)\n",
        "    print('Backtest LGBM → MAE=', round(mae_lgb,3), 'RMSE=', round(rmse_lgb,3))\n",
        "else:\n",
        "    mae_lgb = rmse_lgb = np.nan\n",
        "    print('LGBM: features não encontradas — pulei o backtest')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af4d22de",
      "metadata": {
        "id": "af4d22de"
      },
      "source": [
        "## Comparação entre modelos (holdout + backtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10fc218e",
      "metadata": {
        "id": "10fc218e"
      },
      "outputs": [],
      "source": [
        "# Tabela final (preenche com os números do seu holdout conhecido)\n",
        "holdout = pd.DataFrame({\n",
        "    'modelo': ['LGBM (calibrado)', 'SARIMAX'],\n",
        "    'MAE_holdout': [0.2966, 0.3618],\n",
        "    'RMSE_holdout': [0.3481, 0.4329]\n",
        "})\n",
        "\n",
        "backtest = pd.DataFrame({\n",
        "    'modelo': ['LGBM (expanding)', 'SARIMAX (expanding)'],\n",
        "    'MAE_backtest': [mae_lgb if 'mae_lgb' in globals() else np.nan, mae_sx],\n",
        "    'RMSE_backtest': [rmse_lgb if 'rmse_lgb' in globals() else np.nan, rmse_sx]\n",
        "})\n",
        "\n",
        "cmp = holdout.merge(backtest, how='outer', on='modelo')\n",
        "cmp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37bf5568",
      "metadata": {
        "id": "37bf5568"
      },
      "source": [
        "\n",
        "## Previsões finais (2025) com intervalo de confiança — SARIMAX\n",
        "Cenário baseline: exógenas persistidas (mantidas no último valor observado).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a45af377",
      "metadata": {
        "id": "a45af377"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "# Ajuste final e forecast para 2 trimestres\n",
        "H=2\n",
        "X_all = X.loc[y.index] if 'X' in globals() and X is not None else None\n",
        "res_all = SARIMAX(y, exog=X_all, order=(1,1,2), seasonal_order=(1,0,1,4),\n",
        "                  enforce_stationarity=False, enforce_invertibility=False).fit(disp=0)\n",
        "\n",
        "X_fut = None\n",
        "if X_all is not None:\n",
        "    last = X_all.iloc[[-1]].copy()\n",
        "    X_fut = pd.concat([last]*H, ignore_index=True)\n",
        "\n",
        "fc = res_all.get_forecast(steps=H, exog=X_fut)\n",
        "pred = fc.predicted_mean\n",
        "ci   = fc.conf_int()\n",
        "\n",
        "future_idx = pd.period_range(y.index[-1].to_period('Q')+1, periods=H, freq='Q').to_timestamp()\n",
        "forecast = pd.DataFrame({'pred':pred.values, 'ci_low':ci.iloc[:,0].values, 'ci_high':ci.iloc[:,1].values}, index=future_idx)\n",
        "forecast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891e048a",
      "metadata": {
        "id": "891e048a"
      },
      "outputs": [],
      "source": [
        "# Gráfico do forecast\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(y.index, y, label='real')\n",
        "plt.plot(forecast.index, forecast['pred'], marker='o', label='forecast SARIMAX')\n",
        "plt.fill_between(forecast.index, forecast['ci_low'], forecast['ci_high'], alpha=0.2, label='IC 95%')\n",
        "plt.title('Forecast 2025 (Q3–Q4) – SARIMAX')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7469f428",
      "metadata": {
        "id": "7469f428"
      },
      "source": [
        "# Cronograma\n",
        "\n",
        "##  Etapas 1 e 2:  (20/08/2025 — 26/09/2025)\n",
        "| Nº | ATIVIDADE | RESPONSÁVEL | DATA INÍCIO | DATA TÉRMINO | STATUS |\n",
        "|----|-----------|----------------|-------------|--------------|--------|\n",
        "| 1 | Definição do título e escopo do projeto | Todos | 20/08/2025 | 07/09/2025 | Concluído |\n",
        "| 2 | Identificação do grupo (nomes e matrículas) | Todos | 20/08/2025 | 07/09/2025 | Concluído |\n",
        "| 3 | Redação da Introdução, Motivação e Justificativa | Todos | 20/08/2025 | 07/09/2025 | Concluído |\n",
        "| 4 | Formulação de Objetivo Geral e Objetivos Específicos | Todos | 20/08/2025 | 07/09/2025 | Concluído |\n",
        "| 5 | Descrição da base de dados e variáveis exógenas (CAGED, SELIC) | Franciele / Guilherme | 20/08/2025 | 07/09/2025 | Concluído |\n",
        "| 6 | Justificativa metodológica e bibliografia inicial | Aline / Giovanna | 20/08/2025 | 07/09/2025 | Concluído |\n",
        "| 7 | Planejamento inicial (pipeline + subetapas) | Todos | 20/08/2025 | 25/09/2025 | Concluído |\n",
        "| 8 | Elaboração da Entrega 2 (introdução, referencial, pipeline, cronograma) | Todos | 10/09/2025 | 25/09/2025 | Concluído |\n",
        "\n",
        "---\n",
        "\n",
        "## Etapa 3: Implementação Parcial (25/09/2025 — 31/10/2025)\n",
        "| Nº | Atividade | Responsável(s) | Data início | Data término | Status |\n",
        "|----|-----------|----------------|-------------|--------------|--------|\n",
        "| 9 | Aquisição e integração dos arquivos brutos (CAGED + SELIC) | Guilherme / Fran | 25/09/2025 | 28/09/2025 | Concluído |\n",
        "| 10 | Pré-processamento e montagem da série mensal consolidada | Fran / Aline | 29/09/2025 | 06/10/2025 | Concluído |\n",
        "| 11 | Engenharia de features exógenas (SELIC, lags, médias móveis) | Guilherme / Giovanna | 29/09/2025 | 06/10/2025 | Planejado |\n",
        "| 12 | Análise Exploratória de Dados (EDA) e visualizações | Giovanna / Aline | 07/10/2025 | 13/10/2025 | Planejado |\n",
        "| 13 | Diagrama da solução (fluxo visual do pipeline) | Todos | 07/10/2025 | 10/10/2025 | Planejado |\n",
        "| 14 | Definição final dos modelos candidatos (ARIMA, SARIMA, SARIMAX) | Todos | 14/10/2025 | 16/10/2025 | Planejado |\n",
        "| 15 | Treinamento inicial dos modelos clássicos | Aline / Guilherme | 17/10/2025 | 20/10/2025 | Planejado |\n",
        "| 16 | Treinamento de baseline com redes neurais (opcional) | Giovanna / Fran | 21/10/2025 | 24/10/2025 | Planejado |\n",
        "| 17 | Avaliação preliminar e ajustes iniciais | Todos | 25/10/2025 | 28/10/2025 | Planejado |\n",
        "| 18 | Consolidação da Entrega 3 (notebook parcial) | Todos | 29/10/2025 | 31/10/2025 | Planejado |\n",
        "\n",
        "---\n",
        "\n",
        "## Etapa 4: Implementação Final (01/11/2025 — 28/11/2025)\n",
        "| Nº | Atividade | Responsável(s) | Data início | Data término | Status |\n",
        "|----|-----------|----------------|-------------|--------------|--------|\n",
        "| 19 | Avaliação final e tuning dos modelos | Todos | 01/11/2025 | 05/11/2025 | Planejado |\n",
        "| 20 | Geração dos resultados finais (métricas + gráficos + forecast 2025) | Fran / Aline | 06/11/2025 | 10/11/2025 | Planejado |\n",
        "| 21 | Discussão e conclusão crítica (qualidades, limitações, melhorias) | Giovanna / Guilherme | 11/11/2025 | 15/11/2025 | Planejado |\n",
        "| 22 | Redação dos resultados e organização no notebook | Todos | 16/11/2025 | 20/11/2025 | Planejado |\n",
        "| 23 | Revisão final e formatação ABNT nas referências | Todos | 21/11/2025 | 23/11/2025 | Planejado |\n",
        "| 24 | Preparação da apresentação (slides + vídeo) | Todos | 24/11/2025 | 26/11/2025 | Planejado |\n",
        "| 25 | Submissão final no GitHub + vídeo | Todos | 27/11/2025 | 28/11/2025 | Planejado |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91582a3c",
      "metadata": {
        "id": "91582a3c"
      },
      "source": [
        "**Referências**\n",
        "- INSTITUTO BRASILEIRO DE GEOGRAFIA E ESTATÍSTICA (IBGE). Pesquisa Nacional por Amostra de Domicílios Contínua – PNAD Contínua. Disponível em: https://www.ibge.gov.br\n",
        ". Acesso em: 25 set. 2025.\n",
        "\n",
        "- MINISTÉRIO DO TRABALHO E EMPREGO (MTE). Cadastro Geral de Empregados e Desempregados – CAGED (Microdados). Disponível em: ftp://ftp.mtps.gov.br/pdet/microdados/\n",
        ". Acesso em: 25 set. 2025.\n",
        "\n",
        "- BANCO CENTRAL DO BRASIL (BACEN). Sistema Gerenciador de Séries Temporais – Taxa Selic. Disponível em: https://www.bcb.gov.br\n",
        ". Acesso em: 25 set. 2025.\n",
        "\n",
        "- AGÊNCIA GOV. Desocupação cai para 6,4%, segunda menor taxa da série histórica. Brasília: EBC, 31 out. 2024. Disponível em: https://agenciagov.ebc.com.br\n",
        ". Acesso em: 25 set. 2025.\n",
        "\n",
        "- GOVERNO FEDERAL. Informativo PNAD 2025 – Emprego e Renda. Brasília: Governo do Brasil, 2025. Disponível em: https://www.gov.br\n",
        ". Acesso em: 25 set. 2025.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89076357",
      "metadata": {
        "id": "89076357"
      },
      "source": [
        "## Avaliação (preencha para calcular a Nota Final no template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "235785f7",
      "metadata": {
        "id": "235785f7"
      },
      "outputs": [],
      "source": [
        "# Entradas simples (0 a 10)\n",
        "EDA_e_preprocessamento = 10  #@param {type:\"number\"}\n",
        "Modelo_base = 10              #@param {type:\"number\"}\n",
        "\n",
        "nota = 0.50*EDA_e_preprocessamento + 0.50*Modelo_base\n",
        "print(f'Nota final do trabalho {nota:.1f}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}